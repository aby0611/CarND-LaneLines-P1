{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "import imageio\n",
    "\n",
    "imageio.plugins.ffmpeg.download()\n",
    "%matplotlib inline\n",
    "\n",
    "# All parameters\n",
    "red_threshold = 200\n",
    "green_threshold = 200\n",
    "blue_threshold = 200\n",
    "\n",
    "left_bottom = [0, 539]\n",
    "right_bottom = [900, 539]\n",
    "apex = [475, 320]\n",
    "\n",
    "# Parameters for Canny \n",
    "low_threshold = 50\n",
    "high_threshold = 150\n",
    "\n",
    "# Parameters for Hough transform\n",
    "rho = 2\n",
    "theta = np.pi/180\n",
    "threshold = 15\n",
    "min_line_length = 40\n",
    "max_line_gap = 20\n",
    "\n",
    "def draw_lines(image):\n",
    "    # 0. Init variables\n",
    "    ysize = image.shape[0]\n",
    "    xsize = image.shape[1]\n",
    "    rgb_threshold = [red_threshold, green_threshold, blue_threshold]\n",
    "\n",
    "    # 1. Define color_thresholds for obtaining the boolean matrix \n",
    "    #    to identify pixels below the thresholds.\n",
    "    color_thresholds = (image[:,:,0] < rgb_threshold[0]) \\\n",
    "            | (image[:,:,1] < rgb_threshold[1]) \\\n",
    "            | (image[:,:,2] < rgb_threshold[2])  \n",
    "\n",
    "    # 2. Find the region inside the lines and then identify region_thresholds based on the lines. \n",
    "    fit_left = np.polyfit((left_bottom[0], apex[0]), (left_bottom[1], apex[1]), 1)\n",
    "    fit_right = np.polyfit((right_bottom[0], apex[0]), (right_bottom[1], apex[1]), 1)\n",
    "    fit_bottom = np.polyfit((left_bottom[0], right_bottom[0]), (left_bottom[1], right_bottom[1]), 1)\n",
    "\n",
    "    XX, YY = np.meshgrid(np.arange(0, xsize), np.arange(0, ysize))\n",
    "    region_thresholds = (YY > (XX*fit_left[0] + fit_left[1])) & \\\n",
    "                        (YY > (XX*fit_right[0] + fit_right[1])) & \\\n",
    "                        (YY < (XX*fit_bottom[0] + fit_bottom[1]))\n",
    "\n",
    "    # 3. Covert the image to grayscale.\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # 4. Getting Canny edges.\n",
    "    kernel_size = 3 # Must be an odd number (3, 5, 7...)\n",
    "    blur_gray = cv2.GaussianBlur(gray,(kernel_size, kernel_size),0)\n",
    "    edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "\n",
    "    # 5. Run Hough on edge detected image.\n",
    "    lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),\n",
    "                            min_line_length, max_line_gap)\n",
    "    # 6. Draw the lines from Hough edge detecyed image if it's contained in region_thresholds of step 2.\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            #If (x1,y1),(x2,y2) line is contained in region_thresholds, draw the red line\n",
    "            if region_thresholds[y1][x1] & region_thresholds[y2][x2]:\n",
    "                cv2.line(image,(x1,y1),(x2,y2),(255,0,0), 10)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video solidWhiteRight_output.mp4\n",
      "[MoviePy] Writing video solidWhiteRight_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:11<00:00, 18.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: solidWhiteRight_output.mp4 \n",
      "\n",
      "CPU times: user 8.68 s, sys: 2.58 s, total: 11.3 s\n",
      "Wall time: 12.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"300\" controls>\n",
       "  <source src=\"solidWhiteRight_output.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_clip_output = 'solidWhiteRight_output.mp4'\n",
    "test_clip = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "\n",
    "new_clip = test_clip.fl_image(draw_lines)\n",
    "%time new_clip.write_videofile(new_clip_output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"300\" controls>\n",
    "  <source src=\"{0}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(new_clip_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video solidYellowLeft_output.mp4\n",
      "[MoviePy] Writing video solidYellowLeft_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:39<00:00, 18.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: solidYellowLeft_output.mp4 \n",
      "\n",
      "CPU times: user 28.1 s, sys: 8.16 s, total: 36.2 s\n",
      "Wall time: 40.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"300\" controls>\n",
       "  <source src=\"solidYellowLeft_output.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_clip_output = 'solidYellowLeft_output.mp4'\n",
    "test_clip = VideoFileClip(\"solidYellowLeft.mp4\")\n",
    "\n",
    "new_clip = test_clip.fl_image(draw_lines)\n",
    "%time new_clip.write_videofile(new_clip_output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"300\" controls>\n",
    "  <source src=\"{0}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(new_clip_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
